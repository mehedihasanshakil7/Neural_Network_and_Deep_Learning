{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "515d7aff",
   "metadata": {},
   "source": [
    "# Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "047fa49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c96d59",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e88211c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "48a01af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000, 10), (10000, 784), (10000, 10))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363b7221",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c69573cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.d1 = tf.keras.layers.Dense(8, activation='relu')\n",
    "        self.d2 = tf.keras.layers.Dense(4, activation='relu')\n",
    "        self.d3 = tf.keras.layers.Dense(4, activation='relu')\n",
    "        self.out = tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.d1(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.d3(x)\n",
    "        return self.out(x)\n",
    "    \n",
    "gradient_tape_model = MLP()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eea233",
   "metadata": {},
   "source": [
    "# Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0417520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eac0094",
   "metadata": {},
   "source": [
    "# Training loop (using gradient tape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "76133853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss = 0.5580, Validation Loss = 0.4668, Validation Accuracy = 0.8665\n",
      "Epoch 2: Training Loss = 0.6198, Validation Loss = 0.4542, Validation Accuracy = 0.8717\n",
      "Epoch 3: Training Loss = 0.3552, Validation Loss = 0.4032, Validation Accuracy = 0.8862\n",
      "Epoch 4: Training Loss = 0.3718, Validation Loss = 0.4021, Validation Accuracy = 0.8849\n",
      "Epoch 5: Training Loss = 0.5964, Validation Loss = 0.4028, Validation Accuracy = 0.8848\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_test_split = int(0.8 * len(x_train))\n",
    "trainX = x_train[0:train_test_split]\n",
    "trainY = y_train[0:train_test_split]\n",
    "valX = x_train[train_test_split:]\n",
    "valY = y_train[train_test_split:]\n",
    "# Create training dataset\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((trainX, trainY))\n",
    "train_ds = train_ds.shuffle(buffer_size=10000).batch(BATCH_SIZE)\n",
    "\n",
    "# Create validation dataset\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((valX, valY))\n",
    "val_ds = val_ds.batch(BATCH_SIZE)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Training loop\n",
    "    for x_batch, y_batch in train_ds:\n",
    "        with tf.GradientTape() as tape:\n",
    "            probs = gradient_tape_model(x_batch)\n",
    "            loss = loss_fn(y_batch, probs)\n",
    "        grads = tape.gradient(loss, gradient_tape_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, gradient_tape_model.trainable_variables))\n",
    "\n",
    "    # Validation loop\n",
    "    val_losses = []\n",
    "    val_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "    for x_val_batch, y_val_batch in val_ds:\n",
    "        val_probs = gradient_tape_model(x_val_batch)\n",
    "        val_loss = loss_fn(y_val_batch, val_probs)\n",
    "        val_losses.append(val_loss.numpy())\n",
    "        val_accuracy.update_state(y_val_batch, val_probs)\n",
    "\n",
    "    val_loss_avg = sum(val_losses) / len(val_losses)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Training Loss = {loss.numpy():.4f}, \"\n",
    "          f\"Validation Loss = {val_loss_avg:.4f}, \"\n",
    "          f\"Validation Accuracy = {val_accuracy.result().numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047a7c27",
   "metadata": {},
   "source": [
    "# Training using model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "141ef054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.5525 - loss: 1.3005 - val_accuracy: 0.8176 - val_loss: 0.6090\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8248 - loss: 0.5948 - val_accuracy: 0.8478 - val_loss: 0.5207\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8519 - loss: 0.5118 - val_accuracy: 0.8611 - val_loss: 0.4828\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8628 - loss: 0.4773 - val_accuracy: 0.8668 - val_loss: 0.4674\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8699 - loss: 0.4589 - val_accuracy: 0.8712 - val_loss: 0.4567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x77ef8d735060>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and compile the model\n",
    "keras_fit_model = MLP()\n",
    "keras_fit_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train using fit\n",
    "keras_fit_model.fit(x_train, y_train, batch_size=128, epochs=5, validation_split=0.2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da280f4",
   "metadata": {},
   "source": [
    "# Model evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4fab9908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, x_test):\n",
    "    y_pred_prob = model(x_test)\n",
    "    y_pred = tf.argmax(y_pred_prob, axis=1)\n",
    "    y_true = tf.argmax(y_test, axis=1)\n",
    "\n",
    "    acc = tf.reduce_mean(tf.cast(tf.equal(y_pred, y_true), tf.float32))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "95867cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Tape model accuracy: 87.81%\n",
      "Keras fit model accuracy: 87.57%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gradient Tape model accuracy: {evaluate(gradient_tape_model, x_test) * 100:.2f}%\")\n",
    "print(f\"Keras fit model accuracy: {evaluate(keras_fit_model, x_test) * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU from Pyenv)",
   "language": "python",
   "name": "pyenv-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
